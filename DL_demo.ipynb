{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64444485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in c:\\anaconda\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: psutil in c:\\anaconda\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: humanize in c:\\anaconda\\lib\\site-packages (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "# memory footprint support libraries/code\n",
    "\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eed7276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd74c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)\n",
    "random.seed(47)\n",
    "torch.cuda.manual_seed(47)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73986c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./model_currency.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38324a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'F:\\A currency dataset\\Bd Currency\\Custom\\Train'\n",
    "image_path=[]\n",
    "target=[]\n",
    "for i in os.listdir(path):\n",
    "    for j in os.listdir(os.path.join(path,i)):\n",
    "        image_path.append(os.path.join(path,i,j))\n",
    "        target.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cefa195",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'image_path': image_path, 'target': target}\n",
    "train_df = pd.DataFrame(data=table)\n",
    "train_df = train_df.sample(frac = 1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cadc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'F:\\A currency dataset\\Bd Currency\\Custom\\Test'\n",
    "image_path=[]\n",
    "target=[]\n",
    "for i in os.listdir(path):\n",
    "    for j in os.listdir(os.path.join(path,i)):\n",
    "        image_path.append(os.path.join(path,i,j))\n",
    "        target.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2edf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'image_path': image_path, 'target': target}\n",
    "test_df = pd.DataFrame(data=table)\n",
    "test_df = test_df.sample(frac = 1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1b1315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F:\\A currency dataset\\Bd Currency\\Custom\\Train...</td>\n",
       "      <td>Ten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F:\\A currency dataset\\Bd Currency\\Custom\\Train...</td>\n",
       "      <td>5Hundred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F:\\A currency dataset\\Bd Currency\\Custom\\Train...</td>\n",
       "      <td>Fifty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F:\\A currency dataset\\Bd Currency\\Custom\\Train...</td>\n",
       "      <td>5Hundred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F:\\A currency dataset\\Bd Currency\\Custom\\Train...</td>\n",
       "      <td>5Hundred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path    target\n",
       "0  F:\\A currency dataset\\Bd Currency\\Custom\\Train...       Ten\n",
       "1  F:\\A currency dataset\\Bd Currency\\Custom\\Train...  5Hundred\n",
       "2  F:\\A currency dataset\\Bd Currency\\Custom\\Train...     Fifty\n",
       "3  F:\\A currency dataset\\Bd Currency\\Custom\\Train...  5Hundred\n",
       "4  F:\\A currency dataset\\Bd Currency\\Custom\\Train...  5Hundred"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc84d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e532a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e50b777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550ddc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.isfinite(train_df['target']).all())\n",
    "#print(np.isfinite(test_df['target']).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e6b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(subset=['target'])\n",
    "test_df = test_df.dropna(subset=['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8cb8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['target'].fillna(0)\n",
    "test_df['target'] = test_df['target'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33081fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_df['target'] = train_df['target'].fillna(0)\n",
    "test_df['target'] = test_df['target'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d387da55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabel_mapping = {\"5Hundred\": 0,\\n                \"1Hundred\": 1,\\n                \"2Hundred\": 2,\\n                \"Ten\": 3,\\n                \"Fifty\": 4,\\n                \"Twenty\": 5,\\n                \"1Thousands\": 6}\\ntrain_df[\\'target\\'] = train_df[\\'target\\'].map(label_mapping).astype(int)\\ntest_df[\\'target\\'] = test_df[\\'target\\'].map(label_mapping).astype(int)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "label_mapping = {\"5Hundred\": 0,\n",
    "                \"1Hundred\": 1,\n",
    "                \"2Hundred\": 2,\n",
    "                \"Ten\": 3,\n",
    "                \"Fifty\": 4,\n",
    "                \"Twenty\": 5,\n",
    "                \"1Thousands\": 6}\n",
    "train_df['target'] = train_df['target'].map(label_mapping).astype(int)\n",
    "test_df['target'] = test_df['target'].map(label_mapping).astype(int)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8515224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_mapping = {\"5Hundred\": 0,\n",
    "                \"1Hundred\": 1,\n",
    "                \"2Hundred\": 2,\n",
    "                \"Ten\": 3,\n",
    "                \"Fifty\": 4,\n",
    "                \"Twenty\": 5,\n",
    "                \"1Thousands\": 6}\n",
    "le = LabelEncoder()\n",
    "train_df['target'] = le.fit_transform(train_df['target'])\n",
    "test_df['target'] = le.fit_transform(test_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099508ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "x=test_df.target.value_counts()\n",
    "sns.barplot(x = x.index,y = x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b4a8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataframe,transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        image = self.dataframe.iloc[index]['image_path']\n",
    "        image = cv2.imread(image)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = int(self.dataframe.iloc[index][\"target\"])\n",
    "        return {\"image\": torch.tensor(image, dtype=torch.float), \"targets\": torch.tensor(label, dtype = torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919b958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(classes=7):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features = features, out_features = classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6a4da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms,datasets,models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "model = get_model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ec309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "615379c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer  = optim.Adam(model.parameters(),lr = 0.00003)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_dataset = CustomDataset(\n",
    "dataframe=train_df,\n",
    "transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n",
    "valid_dataset = CustomDataset(\n",
    "dataframe=test_df,\n",
    "transform=test_transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d03d2932eb843e3b231c0af3f6fbf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a922a1d0234fbda6a9d27765fae5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f54845c3529400a8d97f327a325e0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/15\n",
      "ACCURACY: 36.61%\n",
      "LOSS: 23.0442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b15fb4942147de8d8a650f69aec77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ... (your previous code)\n",
    "\n",
    "# Modify the DataLoader creation\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ... (your previous code)\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in tqdm(range(15), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "\n",
    "    for data_in_model in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs = data_in_model['image']\n",
    "        targets = data_in_model['targets']\n",
    "\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_in_model in tqdm(valid_loader, desc=\"Evaluating\"):\n",
    "            inputs = data_in_model['image']\n",
    "            targets = data_in_model['targets']\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            targets = targets.cpu().numpy().tolist()\n",
    "            predictions = predictions.cpu().numpy().tolist()\n",
    "\n",
    "            final_targets.extend(targets)\n",
    "            final_outputs.extend(predictions)\n",
    "\n",
    "    acc = (np.array(final_outputs) == np.array(final_targets)).mean() * 100\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(\"EPOCH: {}/15\".format(epoch + 1))\n",
    "    print(\"ACCURACY: {:.2f}%\".format(acc))\n",
    "    print(\"LOSS: {:.4f}\".format(val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaab2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
